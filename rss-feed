<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<rss version="2.0"><channel><title>yacn.me</title><link>http://yacn.me</link><description>Yet Another Clever Name</description><item><title>Evolution of Scrum at BitSight</title><link>http://yacn.me/2014/04/11/scrumvolution/</link><pubDate>Fri, 11 Apr 2014 00:00:00 -0400</pubDate><description>&lt;h1&gt;The Evolution of Scrum at BitSight&lt;/h1&gt;&lt;p&gt;At Northeastern University, I am in a 5-year program which allows for me to take 4 years of classes while also obtaining 18 months of work experience. I completed my first co-op at &lt;a href=&quot;https://www.bitsighttech.com/&quot;&gt;BitSight Technologies&lt;/a&gt; (and am currently still working there part-time and will be returning for my second), which practices agile project management using &lt;a href=&quot;https://en.wikipedia.org/wiki/Scrum_%28software_development%29&quot;&gt;Scrum&lt;/a&gt;. Working at BitSight was my first experience with Scrum and it has been interesting to watch how its user has evolved over the last 11 months. When I started in May of 2013, BitSight was much smaller. The Engineering team consisted of about 10 full-time staff with about 5 graduate-student co-ops. At this point, standups still consisted of everybody meeting together around the kanban board. Eventually, as more full time staff and co-ops were hired, this became very unsustainable as standups were taking ~30 minutes to complete as 20 people is far too many (5 - 7 being the ideal amount). This was noticed fairly quickly and standups now consist only the necessary representatives from each team / project. The standups are still slightly larger than ideal, but I predict that as BitSight continues to grow, the standups will eventually branch off into smaller, more-focused groups.&lt;/p&gt;&lt;p&gt;Additionally, the Scrum Master initially was an employee who had been, for lack of a better phrase, stuck with it. They knew the basics, but not enough to efficiently lead the meetings and optimize team velocity. When a new engineer with Scrum experience was hired, they eventually took the reigns as Scrum Master and turned it around. This passing of the torch has lead to a rotating Scrum Master. That is, every so often, a new employee is trained how to be Scrum Master and then proceeds to lead the standups until eventually the next employee is selected and the cycle repeats. I think this is a brilliant plan, as it gets everyone more involved in the Scrum process which means that everyone will have a more detailed understanding of how it works (and why), leading to increased focus and increased agility. It will definitely be interesting to see how BitSight continues to change as it grows bigger and bigger.&lt;/p&gt;</description></item><item><title>&quot;The Corruption of Agile&quot; Response</title><link>http://yacn.me/2014/04/04/corruption-of-agile/</link><pubDate>Fri, 4 Apr 2014 00:00:00 -0400</pubDate><description>&lt;h1&gt;&quot;The Corruption of Agile&quot; Response&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;http://www.drdobbs.com/architecture-and-design/the-corruption-of-agile/240166698&quot;&gt;The Corruption of Agile&lt;/a&gt; is (yet another) article detailing how the agile movement has deviated from a set of values to a set of practices, with a pseudo-religious tone surrounding said practices. The article argues that this shift from values to practices was heavily influenced by the vast number of &quot;Agile consultants&quot;, who took the set of values stated in the Agile manifesto and translated them into rote programming practices, which the article argues loses the original values. In the end, the article argues that whether or not a company can be called agile depends on the culture of said company and not the practices the company uses. Now, I do agree with this point, as I have heard of many companies simply wanting to &quot;buy agile&quot;, i.e. pay for a consultant to come in, run a few seminars, take their check, and leave. Tada, now we're agile! Now lets keep doing everything the same way as before, but now we're &quot;agile&quot;. Right? Wrong. The article's conclusion is simply a prettier way of saying &quot;if you want to call yourself agile, you need to put up or shut up&quot;.&lt;/p&gt;&lt;p&gt;One point that struct a chord with me while reading was the author's constant comparison of TDD to some sort of religious movement. While they do have a point when they're refering to the fanatics, i.e. those who see any other way of doing things as incorrect, I don't believe that this should discount the entire methodology. In a &lt;a href=&quot;http://www.drdobbs.com/architecture-and-design/addressing-the-corruption-of-agile/240166890&quot;&gt;follow up&lt;/a&gt;, the author admits that the test coverage provided by TDD is valuable, though they argue that the same benefit could be reaped if tests are written after the fact. I do not disagree with this statement, the most important part of test-driven development is the resulting tests that you use to validate your code works correctly. However, I do believe that by following TDD practices writing tests is easier, simply because you're writing your tests while also writing your code, meaning you have the idea of what you want this function to do already in your head. When writing tests first, I've found it much easier to understand the full scope of the problem being worked on, which often leads to me implementing a better solution overall. In the end, as long as the test coverages are equal, it really doesn't matter how you get there, as long as you get there, I just find TDD makes it easier to get there.&lt;/p&gt;</description></item><item><title>&quot;Dia&quot; Review</title><link>http://yacn.me/2014/03/20/dia-review/</link><pubDate>Thu, 20 Mar 2014 00:00:00 -0400</pubDate><description>&lt;h1&gt;&quot;Dia&quot; Review&lt;/h1&gt;&lt;h2&gt;Overview&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://wiki.gnome.org/Apps/Dia/&quot;&gt;Dia&lt;/a&gt; (pronounced &quot;dee-a&quot;), is FOSS tool used for general-purpose diagramming which runs on all major platforms (*nix, Windows, Mac OS X).&lt;/p&gt;&lt;h2&gt;Finding Dia&lt;/h2&gt;&lt;p&gt;I found Dia when searching for a diagramming tool that I could run locally on my own machine instead of needing internet access to use one of the various SaaS diagramming tools, such as &lt;a href=&quot;https://creately.com&quot;&gt;Creatly&lt;/a&gt; or &lt;a href=&quot;https://www.lucidchart.com&quot;&gt;Lucidchart&lt;/a&gt;. Additionally, I wanted something that was free. This was both out of cheapness on my part (I don't often diagram things so it seems like a waste of money to pay for something I won't use) and due to frustration with the freemium SaaS offerings mentioned. The frustration stems from various features of the services only being available to members who pay, such as the ability to export your diagrams in a variety of formats or a limiting the set of shapes and objects you can use in your diagrams and still be able to export it. Dia satisfies all of these requirements and I have been using it for all of my diagramming needs since the end of February.&lt;/p&gt;&lt;h2&gt;User Experience&lt;/h2&gt;&lt;p&gt;Dia's UX, compared to the UX offered by tools like Crealy, Lucidchart, Gliffy, or OmniGraffle, is very rough. The application itself uses &lt;a href=&quot;https://en.wikipedia.org/wiki/GTK%2B&quot;&gt;GTK+&lt;/a&gt; to manage it's UI, which means the developers only need to write their UI for GTK+, which then handles displaying the UI on the variety of platforms it runs on. The downside to this approach is that the interface doesn't look native on any platform and doesn't integrate well with any (save for *nix platforms). The slight upside is that users only need to learn one interface, as it will be the same on any platform your application is used on.&lt;/p&gt;&lt;p&gt;Anyways, as I use OS X, the UX was affected even more. While *nix and Windows use the Control key to anchor most of their keyboard shortcuts, OS X uses the Command key. Dia/GTK does not take this into consideration, meaning I need to use the Control key for all keyboard shortcuts, which undermines all the muscle memory developed for standard keyboard shortcuts. Fortunately, it is fairly simple for me to get into the groove of using the Control key as I've used Windows for most of my life, but the initial context-switch can be fairly jarring.&lt;/p&gt;&lt;h2&gt;Worth It?&lt;/h2&gt;&lt;p&gt;The question you must be asking yourself now is, &quot;Does Dia overcome it's rough UX or should I stick with my current tool of choice?&quot;. The answer to this question is &quot;It depends&quot;. If you are going to be doing a lot of charting, I would definitely recommend going with a more commercial solution as it will be better polished and offer more features. However, if you just need a tool to create the occasional UML diagram for a class/homework assignment/one-off project/etc, I highly recommend Dia. The ability to work on my diagrams while not tethered to an internet connection while also being able to export my diagrams in any format I desire in addition to being completely &lt;a href=&quot;https://en.wikipedia.org/wiki/Free_software&quot;&gt;libre&lt;/a&gt; outweighs the jarring UX for me as I feel the above features make it worth it.&lt;/p&gt;</description></item><item><title>&quot;The Visible Ops Handbook&quot; Review</title><link>http://yacn.me/2014/03/11/visible-ops-review/</link><pubDate>Tue, 11 Mar 2014 00:00:00 -0400</pubDate><description>&lt;h1&gt;&quot;The Visible Ops Handbook&quot; Review&lt;/h1&gt;&lt;p&gt;My boss was kind enough to lend me his copy of &lt;a href=&quot;http://www.amazon.com/The-Visible-Ops-Handbook-Implementing/dp/0975568612/&quot;&gt;The Visible Ops Handbook&lt;/a&gt; to read over Spring Break. I'd seen the book recommended many times, so when I saw the distinctive cover on his desk I had to ask about it. My initial reaction was that it was much thinner than I ever thought it would be, I was used to big compsci books and this is certainly not like those. However, short as it may be, there's definitely a lot of really great information packed in there. The book is only about 80 pages, so I was able to finish it on the flight to Indiana for Spring Break. The handbook contains a series of four steps detailing how you can transform your organization into a higher performing one. The four steps are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Stabalize the Patient (Modify First Response)&lt;/li&gt;
  &lt;li&gt;Catch and Release (Find Fragile Artifacts)&lt;/li&gt;
  &lt;li&gt;Establish Repeatable Build Library&lt;/li&gt;
  &lt;li&gt;Enable Continuous Improvement&lt;/li&gt;
&lt;/ol&gt;&lt;h2&gt;Stabalize the Patient&lt;/h2&gt;&lt;p&gt;This step mainly concerns with stabalizing the organization's infrastructure (&quot;the patient&quot;). The biggest point they hit upon is that 80% of outages are caused by the organization themselves. To rememdy this, they focus on change management and control. Tripwire (software which detects changes to specified files) was heavily mentioned here, though that is because one of the authors (Gene Kim) founded Tripwire. They of course mention that alternatives exist, but none are discussed as in-depth (relatively speaking, as in, named) as Tripwire.&lt;/p&gt;&lt;h2&gt;Catch and Release&lt;/h2&gt;&lt;p&gt;This step is a response to a fragile infrastructure, that is, infrastructure that has been created and configured by hand, meaning it is not able to repeatably created and destroyed identically. An inventory must be done of all assets, configurations, and services to find the those which have the lowest successful change rate, the highest MTTR, and the highest downtime costs. Once these assets have been enumerated, the authors suggest that they be &quot;frozen&quot;, meaning no changes are applied to them without good reason. Now that the infrastructure has been inventoried, the organization can focus on creating a provsioning process such that they have identical, repeatable infrastructure that can be easily replicated, which nicely leads into the next step.&lt;/p&gt;&lt;h2&gt;Establish Repeatable Build Library&lt;/h2&gt;&lt;p&gt;This step focuses on implementing an effective release management process by creating repeatable builds for the most important assets, with the end goal being to make it cheaper to rebuild than repair a given server (or, as my boss likes to put it, treating infrastructure like cattle, when one gets sick, just take it out back and shoot it and bring the next one in). &lt;/p&gt;&lt;h2&gt;Enable Continuous Improvement&lt;/h2&gt;&lt;p&gt;The previous steps have focused on building a tight loop of &quot;Release=&amp;gt;Control=&amp;gt;Resolution&quot;. This step focuses on implementing metrics surrounding those process areas, because, as H. James Harrington said:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Measurement is the first step that leads to control and eventually to improvement. If you can't measure something, you can't understand it. If you can't understand it, you can't control it. If you can't control it, you can't improve it.&lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;&lt;a href=&quot;http://www.goodreads.com/quotes/632992-measurement-is-the-first-step-that-leads-to-control-and&quot;&gt;Source&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;I found the handbook to be a fast, concise read. I believe that any Operations Engineer/ System Administrator/etc should read it as it contains many valuable insights into increasing your organizations performance. Highly recommended.&lt;/p&gt;</description></item><item><title>Plex Issue Tracker and Custom Icon Font</title><link>http://yacn.me/2014/03/08/plex-issue-tracker/</link><pubDate>Sat, 8 Mar 2014 00:00:00 -0500</pubDate><description>&lt;h1&gt;Plex Issue Tracker&lt;/h1&gt;&lt;p&gt;I've been hosting a Plex Media Server and sharing it with friends for almost a year now (started once I moved off campus and my internet allowed it) and in that time there's been a few bumps in the road, but overall it has been running quite smoothly. There's been the occasional glitch, e.g the Plex Media Scanner stops running (meaning no new shows are detected) necessitating a restart of the Plex service or the Plex service itself stops working and needs a restart. These issues are minor and take minimal effort to fix as I simply need to RDP in and restart the service. However, there's the occasional issue which requires a bit more manual intervention, such as shows having improper metadata. Since I'm not the only user of the server, there's actually a number of shows present that I do not keep up with at all. What ends up happening is I'll be hanging out with one of my friends and they'll mention some issue they're having with Plex. I then make a mental note to remember to fix it when I return home. Being the human I am, I don't have perfect memory, which means things sometimes slip through the cracks.&lt;/p&gt;&lt;p&gt;With that in mind, I decided to create a place to file support requests for GUNTER, my Plex server. I created a GitHub repository &lt;a href=&quot;https://github.com/yacn/gunter-issues&quot;&gt;gunter-issues&lt;/a&gt; to hold any support requests / issues related to Plex or GUNTER. Using the free service &lt;a href=&quot;https://waffle.io&quot;&gt;waffle.io&lt;/a&gt;, I was able to turn that repo into an &lt;a href=&quot;https://waffle.io/yacn/gunter-issues&quot;&gt;open and online agile/kanban board&lt;/a&gt;. Now, people can file issues with the knowledge that if I forget about it, it's right there on the board. It is my hope that by introducing this, GUNTER/Plex can only improve.&lt;/p&gt;&lt;h3&gt;Plex Info Page and Icon Fonts&lt;/h3&gt;&lt;p&gt;While integrating the issue tracker into this site, I wanted to add a link to the a page containing information and resources about Plex. Since it was going to be in the upper-right corner, I wanted it to fit in with the &lt;a href=&quot;fontawesome.github.io/Font-Awesome/&quot;&gt;Font Awesome&lt;/a&gt; icons I was already using. I came up with the idea of putting together a version of the Plex Media Center logo in the style of the Font Awesome icons.&lt;/p&gt;&lt;p&gt;I started by finding the PMS logo and then modified its coloring to fit in with the Font Awesome icons. I ended up with a PNG with transparency, but then realized that this wouldn't scale well if I wanted to use it at a bigger size. I decided at that point to convert it to an SVG. Unfortunately while the software I used to modify the image (&lt;a href=&quot;http://www.pixelmator.com/&quot;&gt;Pixelmator&lt;/a&gt;) supports creating vector-like graphics, it does not support exporting to SVGs. However, I was able to use a piece of software called &lt;a href=&quot;http://vectormagic.com/desktop&quot;&gt;Vector Magic&lt;/a&gt; to take the PSD exported by Pixelmator and feed it in and with about 5 clicks, I had an SVG!&lt;/p&gt;&lt;p&gt;I then spent quite a bit of time futzing around with the CSS sizing and positioning, trying to get the SVG to appear, but nothing seemed to work. Frustrated and out of ideas, I googled &quot;create own font awesome icons svg&quot; and stumbled upon this awesome RubyGem called &lt;a href=&quot;http://fontcustom.com&quot;&gt;Font Custom&lt;/a&gt;, which takes a directory of SVG files and converts them to a CSS file that you can include on your sites. With this in hand, I was able to convert my SVG into a font and then it was a simple matter of adding an item to the navigation list like all the other links! In the end, I think it looks and feels like a native Font Awesome icon and was well worth the effort to get it going.&lt;/p&gt;</description></item><item><title>Migrating from dvm to boot2docker</title><link>http://yacn.me/2014/03/07/migrate-dvm-to-boot2docker/</link><pubDate>Fri, 7 Mar 2014 00:00:00 -0500</pubDate><description>&lt;h1&gt;Migrating from &lt;code&gt;dvm&lt;/code&gt; to &lt;code&gt;boot2docker&lt;/code&gt;&lt;/h1&gt;&lt;h2&gt;Preconditions&lt;/h2&gt;&lt;p&gt;About two weeks ago, I wrote about how I got &lt;a href=&quot;https://fnichol.github.io/dvm/&quot;&gt;dvm&lt;/a&gt; working with &lt;a href=&quot;https://www.docker.io&quot;&gt;Docker&lt;/a&gt; using a specified network range for the &lt;code&gt;docker0&lt;/code&gt; bridge. A quick overview of dvm, for the uninitiated: It's a Bash script wrapped around a &lt;code&gt;Vagrantfile&lt;/code&gt; which uses a Vagrant box based off the &lt;a href=&quot;http://boot2docker.io&quot;&gt;boot2docker&lt;/a&gt; image. The original boot2docker script itself is simply a Bash script wrapped around the &lt;a href=&quot;http://www.virtualbox.org/manual/ch08.html&quot;&gt;VBoxManage&lt;/a&gt; command. There's an &lt;a href=&quot;https://github.com/boot2docker/boot2docker-cli&quot;&gt;on-going effort&lt;/a&gt; to rewrite the boot2docker script in &lt;a href=&quot;https://golang.org&quot;&gt;Go&lt;/a&gt;, but it is currently experimental. Anyways, dvm uses Vagrant to interact with VirtualBox, where Vagrant itself is a wrapper around interacting with VirtualBox. Since it uses Vagrant, it needs &lt;a href=&quot;https://github.com/mitchellh/boot2docker-vagrant-box/&quot;&gt;a Vagrant Box&lt;/a&gt; to create the VM, meaning that each time a new boot2docker image is released, a new Vagrant Box must also be created before dvm can use the latest version.&lt;/p&gt;&lt;p&gt;You've probably already guessed why I'm migrating away, there's just simply too many moving pieces that can each become a bottleneck. dvm can bottleneck with bugfixes while I can also be bottlenecked by waiting for new Vagrant Boxes to be released. To eliminate this, I have decided to move away from using dvm to using the original boot2docker (I'm actually using boot2docker-cli, the Go port of the tool, but more on that later).&lt;/p&gt;&lt;h2&gt;Moving previous work&lt;/h2&gt;&lt;p&gt;The downside to this is that I needed to find a way to perform the same customizations I was using with dvm to change the network range of the &lt;code&gt;docker0&lt;/code&gt; interface. With dvm, adding local customizations is as simple as editing the provisioning script which is run wheneve the VM is created. Using boot2docker itself wasn't as straight forward. As boot2docker is run entirely from memory, a persistence disk must be attached to the VM to provide a place to save things so they won't be deleted. While dvm handled this in the &lt;code&gt;Vagrantfile&lt;/code&gt;, the boot2docker script actually creates it for you as well and mounts it to &lt;code&gt;/mnt/sda1&lt;/code&gt;. To add local customizations, you can place what you want to do into a script titled &lt;code&gt;bootlocal.sh&lt;/code&gt; and place that inside &lt;code&gt;/var/lib/boot2docker&lt;/code&gt; (which is symlinked to &lt;code&gt;/mnt/sda1/var/lib/boot2docker&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;The tasks I needed to take care of in this script were to:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Install bridge utils if not present&lt;/li&gt;
  &lt;li&gt;Modify Docker's init script to add the &lt;code&gt;--bip&lt;/code&gt; option&lt;/li&gt;
  &lt;li&gt;Create a folder on the persistence disk for use as a mount point for SSHFS&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;To accomplish 1 and 2, I was able to re-use most of the work done in dvm's &lt;code&gt;Vagrantfile&lt;/code&gt;. For 3, it was simply a matter of creating a folder. Once I had written the script, however, I realized I needed to get it on the VM disk before it'd be useful! I could have simply re-typed it while SSH'd into the VM, but that's not very DRY and I'll likely need to add more files to the VM at a later point. Luckily, the boot2docker maintainers &lt;a href=&quot;https://github.com/boot2docker/boot2docker/blob/master/doc/WORKAROUNDS.md#folder-sharing&quot;&gt;provide a workaround&lt;/a&gt; using &lt;a href=&quot;https://osxfuse.github.io&quot;&gt;FUSE for OS X and SSHFS&lt;/a&gt;, so I was able to mount a folder from my host laptop on the VM with minimal fuss.&lt;/p&gt;&lt;p&gt;The one issue I ran into was with the command used to mount the folder. In the steps given, they have you create a file &lt;code&gt;b2d-passwd&lt;/code&gt; containing the password for the docker user on the VM. Then, when you go to mount the folder on the VM, they have you run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sshfs docker@localhost:/mnt/sda1/myapp ~/myapp -oping_diskarb,volname=b2d-myapp -p 2022 -o reconnect -o UserKnownHostsFile=/dev/null -o password_stdin &amp;lt; ~/.boot2docker/b2d-passwd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;where &lt;code&gt;/mnt/sda1/myapp&lt;/code&gt; is the mount-point on the VM and &lt;code&gt;~/myapp&lt;/code&gt; is the folder on the host being shared with the VM. The part that I had issue with was &lt;code&gt;-o password_stdin &amp;lt; ~/.boot2docker/b2d-passwd&lt;/code&gt;. No matter what I tried, I always got a timeout error while waiting for the prompt. When I removed that part of the command, the reason for this became immediately obvious: I was being asked &lt;code&gt;yes/no&lt;/code&gt; about the VM's SSH key, meaning the prompt would never show! As of now, I haven't found a workaround, it is easy enough to type &lt;code&gt;yes&lt;/code&gt; and &lt;code&gt;tcuser&lt;/code&gt; when I want to mount a folder.&lt;/p&gt;&lt;h2&gt;Bumps in the road&lt;/h2&gt;&lt;p&gt;Once that was working, it was trivial to move the &lt;code&gt;bootlocal.sh&lt;/code&gt; script from the shared folder to its place in &lt;code&gt;/var/lib/boot2docker&lt;/code&gt;. Then I simply logged out, stopped the VM, and copied the VMDK to a safe place. Now when I want to create a new boot2docker VM, I just need to copy the VMDK into place (&lt;code&gt;~/.boot2docker&lt;/code&gt;) before running &lt;code&gt;boot2docker init&lt;/code&gt;. Once that completes, I have a fresh VM with all my local customizations. The next logical step for this would be to create a customized ISO that includes the &lt;code&gt;bootlocal.sh&lt;/code&gt; to remove the need to remember to copy the VMDK back into place when creating a new VM.&lt;/p&gt;&lt;p&gt;However, this is where the issues have started springing up. When I tried to run Test Kitchen through the new boot2docker VM, I ran into the issue where &lt;a href=&quot;https://github.com/portertech/kitchen-docker/issues/24&quot;&gt;the VM hangs waiting for the container to be ready&lt;/a&gt;. Reading through that thread it seemed like any issues with the software itself (Test Kitchen, kitchen-docker, boot2docker, docker itself, etc) should have been fixed in the versions I am using (Test Kitchen 1.2.1, kitchen-docker installed from GitHub, boot2docker 0.6.0, docker 0.8.1). This issue seemed familiar though, and upon further digging I narrowed it down to routes getting crossed and confused. Aha! This was why I moved to dvm in the first place. dvm is slightly different from the default boot2docker because it creates a &lt;a href=&quot;http://www.virtualbox.org/manual/ch06.html#network_hostonly&quot;&gt;host-only network&lt;/a&gt; to run Docker on. This solves the issue of criss-crossed routes, so I set out to find if this feature existed in boot2docker.&lt;/p&gt;&lt;p&gt;In my research, I found this &lt;a href=&quot;https://github.com/boot2docker/boot2docker/pull/198&quot;&gt;hostonly interface-related&lt;/a&gt; pull request. At the time of this writing, the pull request is still open, so this feature hasn't made its way into the main boot2docker. Fortunately though, at the bottom of the pull request the discussion gets moved to &lt;a href=&quot;https://github.com/boot2docker/boot2docker-cli/pull/42&quot;&gt;this pull request&lt;/a&gt; on the new &lt;code&gt;boot2docker-cli&lt;/code&gt; repo. That request was merged, so the feature in some form exists. This is why I am as of now using the &lt;code&gt;boot2docker-cli&lt;/code&gt; tool instead of the normal one.&lt;/p&gt;&lt;h2&gt;What's left to do&lt;/h2&gt;&lt;p&gt;Once that was all figured out, my next move was to try to get test kitchen and kitchen-docker working together with this new boot2docker VM. I re-created my VMDK w/ the &lt;code&gt;bootlocal.sh&lt;/code&gt; script and tried to run &lt;code&gt;kitchen test&lt;/code&gt;. Unfortunately, this fails right after pulling in the ubuntu images. Looking through the logs, it seems like the containers are unable to access the Internet. Also, the boot2docker-cli creates a new hostonly interface for each VM it creates, but it also never deletes them after the VMs are deleted. This also leads to issues with criss-crossed routes as packets are being sent to the wrong hostonly interface. Lastly, I seem to be unable to run &lt;code&gt;boot2docker-cli ssh&lt;/code&gt; or &lt;code&gt;boot2docker ssh&lt;/code&gt; to log into the VMs while I'm connected to my work's VPN. This is strange since I was able to use both of those commands just fine while at work, but as soon as I turned my VPN off, they both started working. I suspect it is also an issue of criss-crossed routes. &lt;/p&gt;&lt;p&gt;In summary, the following work is left to do before the migration from dvm to boot2docker is complete:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Figure out why containers cannot reach the internet&lt;/li&gt;
  &lt;li&gt;Modify &lt;code&gt;boot2docker-cli init/delete&lt;/code&gt; to keep track of the interfaces it creates so they can be deleted with the VM.&lt;/li&gt;
  &lt;li&gt;Figure out why I'm unable to SSH into the VM while logged into my work's VPN.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;I've started reading about Go so that I can contribute patches, so hopefully I should be able to make some progress on number 2 before too long. It seems to be a simple matter of creating a map of the interfaces created to the VMs their attached to, but there's all of Go to grapple with first. It's going to be a busy upcoming week too, as the 2014 Northeast CCDC is this Friday, Saturday, and Sunday at UNH. Fun fun fun, so much to do, so little time.&lt;/p&gt;</description></item><item><title>Using a Kanban Board as a To-Do List</title><link>http://yacn.me/2014/03/04/kanban-todo/</link><pubDate>Tue, 4 Mar 2014 00:00:00 -0500</pubDate><description>&lt;h1&gt;Using a Kanban Board as a To-Do List&lt;/h1&gt;&lt;p&gt;Even after missing my flight home for winter break and spending the entire day (8AM to midnight when I was finally picked up by my parents) in the airport, I was still excited. Mostly to finally escape airports and go back to sleep, but also because I knew I had two weeks ahead of me which I could use to do whatever I wanted as it was my free time. I had just finished my first co-op at BitSight where they use Scrum for project management, so I was very used to and in the groove of using a kanban board to visualize all the tasks currently being worked on. I wanted to continue using such a process as I felt it would help me switch into working mode more easily. I found &lt;a href=&quot;https://waffle.io&quot;&gt;waffle.io&lt;/a&gt;, which creates an online kanban board for you based on the issues on a given GitHub repository and the tags associated with said issue. I created an empty repo to use for my todo list and set off to work.&lt;/p&gt;&lt;p&gt;I found through using a kanban board that I was able to work on multiple things at once much easier since it helped to lower the amount of time spent context switching because all of the necessary information was right there in front of me: what I did last time, what there is to do, what's the status of the things I'm working on.&lt;/p&gt;&lt;p&gt;Over the past few months I have sort of left it hanging and unused, not because I didn't find it helpful, but because I've been very busy with my coursework and haven't had much (if any) time for personal projects. Why didn't I use it for my school work you ask? Simply because I already had a workflow and software setup for doing just that. I use &lt;a href=&quot;http://www.istudentpro.com/&quot;&gt;iStudiez Pro&lt;/a&gt; to manage and track my coursework and grades. It's really a joy to use and it makes staying on top of the large workload that much more manageable. There are apps for OS X, the iPhone, as well as the iPad, and you're able to sync your data across all devices with ease, making it easier than ever to stay on top of my coursework.&lt;/p&gt;&lt;p&gt;Once the summer starts, I'll have more free time to devote to personal projects so I'm certain I'll be using said online kanban board again to manage and track my progress, the workflow just makes sense to me.&lt;/p&gt;</description></item><item><title>Sensu EC2 Node Handler</title><link>http://yacn.me/2014/02/24/sensu-ec2-node-handler/</link><pubDate>Mon, 24 Feb 2014 00:00:00 -0500</pubDate><description>&lt;h1&gt;Sensu EC2 Node Handler&lt;/h1&gt;&lt;h2&gt;The Problem&lt;/h2&gt;&lt;p&gt;At work, we run &lt;a href=&quot;https://sensuapp.org&quot;&gt;Sensu&lt;/a&gt; as the base for our metrics, monitoring, and alerting pipeline. A while back, we were running into an issue with phantom keepalive alerts due to how Sensu was determining whether or not a node still existed. The way it was determining this was to query our &lt;a href=&quot;https://www.getchef.com&quot;&gt;Chef&lt;/a&gt; server to check whether or not the client and node existed there. However, due to how we provision and terminate nodes (using an internal knife plugin), the clients and nodes on the Chef server are not removed until the next time they are to be created. (Really, we should update the deletion component to remove the clients and nodes, but it is a low priority at this point).&lt;/p&gt;&lt;p&gt;Due to this workflow, when we would terminate a cluster, we would encounter a &quot;keepalive storm&quot;, where we would be flooded with keepalive alerts for the cluster we just terminated. This would cause our Sensu server to become overloaded with queued up events to handle. When our next Chef run would execute, the Sensu server would be signaled to restart. However, due to the massive event queue that had built up, the time needed to restart the process would exceed the threshold set for the service's script, set in &lt;code&gt;/etc/default/sensu&lt;/code&gt;. I believe the default was 10 seconds, we increased it to 30 while investigating to try and soothe the inevitable Chef runs.&lt;/p&gt;&lt;p&gt;Nevertheless, the process would nearly always fail to restart, which caused the Chef run to fail and would leave teh Sensu server in an incorrect state. The remedy this state, we owuld need to manually stop and start each of the Sensu components (API, server, client) manually. This was very annoying and inconveniencing, so I set out to find a fix for the situation.&lt;/p&gt;&lt;h2&gt;The Solution&lt;/h2&gt;&lt;p&gt;To solve our phantom keepalives and subsequent &quot;keepalive storms&quot;, I created a Sensu handler for the keepalive event. When it handles a keepalive event, instead of checking the Chef server to determine whether the node still exists, it checks EC2. If the node is not found in EC2, it is removed from Sensu as a client.&lt;/p&gt;&lt;p&gt;When we implemented this handler at work, we were able to eliminate the &quot;keepalive storms&quot; and phantom keepalive alerts, thus increasing the stability of our Sensu server. You can check out the plugin in the official &lt;a href=&quot;https://github.com/sensu/sensu-community-plugins/blob/master/handlers/other/ec2_node.rb&quot;&gt;Sensu Community Plugins&lt;/a&gt; repository on GitHub. Hopefully it will be of some use to others.&lt;/p&gt;</description></item><item><title>Fixing dvm with Test Kitchen</title><link>http://yacn.me/2014/02/24/dvm-test-kitchen-docker/</link><pubDate>Mon, 24 Feb 2014 00:00:00 -0500</pubDate><description>&lt;h1&gt;Fixing dvm with Test Kitchen&lt;/h1&gt;&lt;h2&gt;Finding dvm&lt;/h2&gt;&lt;p&gt;For the past few weeks at work, I've been conducting research on the side with the goal of setting up a continuous integration environment for our Chef cookbooks. I've decided to use &lt;a href=&quot;https://kitchen.ci&quot;&gt;Test Kitchen&lt;/a&gt; with the &lt;a href=&quot;https://github.com/portertech/kitchen-docker&quot;&gt;kitchen-docker&lt;/a&gt; driver as the base for our integration testing framework (of which the specifics are out of the scope of this post).&lt;/p&gt;&lt;p&gt;Now that I'd chosen our stack, it was time to get kitchen-docker, Test Kitchen, and Docker working together. I needed a solution which would allow me to work with Docker locally on OS X. Luckily, there are two related projects allowing me to do just that, &lt;a href=&quot;https://github.com/fnichol/dvm&quot;&gt;dvm&lt;/a&gt; and &lt;a href=&quot;https://github.com/boot2docker/boot2docker&quot;&gt;boot2docker&lt;/a&gt; (dvm is actually just a wrapper around Vagrant using a &lt;a href=&quot;https://github.com/mitchellh/boot2docker-vagrant-box&quot;&gt;boot2docker box&lt;/a&gt;).&lt;/p&gt;&lt;h2&gt;Bumpy start&lt;/h2&gt;&lt;p&gt;The first issue I ran into was Docker choosing a network range which conflicted with the network range our work runs in. I'd actually run into this issue before, several months ago when I was first testing out Docker. At the time, there was no immediate workaround, so put it in the back of my mind for later. Docker has since been updated to attempt to be smart about choosing the network range by looking for any conflicting networks. However, this issue still affects us because Docker is being run through a VM, meaning it will not detect the conflicting network.&lt;/p&gt;&lt;p&gt;A more recent addition to Docker is the &lt;code&gt;--bip=&amp;quot;&amp;quot;&lt;/code&gt; option, which you can use to specify a CIDR range for the &lt;code&gt;docker0&lt;/code&gt; bridge that Docker creates. However, to use this new feature with dvm, I was going to need to make some modifications to support it.&lt;/p&gt;&lt;h2&gt;Modifying dvm&lt;/h2&gt;&lt;p&gt;The way dvm works is by allowing you to set configuration options in a file &lt;code&gt;~/.dvm/dvm.conf&lt;/code&gt;. Those settings are environment variables which are exported when creating the boot2docker VM. To add support for &lt;code&gt;--bip&lt;/code&gt;, I added the configuration directive &lt;code&gt;DOCKER0_CIDR&lt;/code&gt; to the config file. I then modified the &lt;code&gt;Vagrantfile&lt;/code&gt; to use the new argument if specified. I saved my changes, crossed my fingers, and typed &lt;code&gt;dvm up&lt;/code&gt;. To my dismay, passing in that option didn't seem to affect anything!&lt;/p&gt;&lt;h2&gt;(Re)building the bridge&lt;/h2&gt;&lt;p&gt;After some more reading, I learned that if the &lt;code&gt;docker0&lt;/code&gt; bridge has already been created, the IP range assigned to it will not be affected by the &lt;code&gt;--bip&lt;/code&gt; option. To use the option, you need to first make sure the &lt;code&gt;docker0&lt;/code&gt; bridge does not exist when starting Docker, meaning that if it does exist, it will need to be deleted.&lt;/p&gt;&lt;p&gt;Deleting a bridge seems simple enough, you just need to run &lt;code&gt;brctl delbr nameofbridge&lt;/code&gt;. Unfortunately, the &lt;code&gt;brctl&lt;/code&gt; utility is not included in the release of &lt;a href=&quot;http://www.tinycorelinux.net/&quot;&gt;Tiny Core Linux&lt;/a&gt; used by boot2docker. I now set off to find a bridge-utils package I could install on the distro. Fortunately I didn't need to dig for too long, there was a link to such a package in &lt;a href=&quot;https://github.com/boot2docker/boot2docker/blob/master/doc/FAQ.md&quot;&gt;one of the docs&lt;/a&gt; for boot2docker.&lt;/p&gt;&lt;p&gt;Now all I needed to do was update the &lt;code&gt;Vagrantfile&lt;/code&gt; to check whether or not the &lt;code&gt;DOCKER0_CIDR&lt;/code&gt; option was set, and if so, setup the arguments, stop the currently running Docker daemon, install the bridge utils, and remove the &lt;code&gt;docker0&lt;/code&gt; bridge. I ran &lt;code&gt;dvm up&lt;/code&gt; and low and behold, it worked!&lt;/p&gt;&lt;p&gt;By this time I'm feeling pretty good, I've gotten much farther than ever before. I run &lt;code&gt;kitchen create&lt;/code&gt; to create a container and, you guessed it, it worked! Running &lt;code&gt;kitchen converge&lt;/code&gt; also worked as expected, which is great as now my container can access hosts within our local network as well as the internet at large! Satisfied with myself, I ran &lt;code&gt;kitchen destroy&lt;/code&gt; to delete the containers. Oh no, it doesn't work!&lt;/p&gt;&lt;h2&gt;One last jam&lt;/h2&gt;&lt;p&gt;Unfortunately I ran into a jam (damn you Chris Christie!), running &lt;code&gt;kitchen destroy&lt;/code&gt; throws an exception! Looking at the message returned, it seems to be an issue related with trying to stop and remove the container, something appears to be holding a lock over it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;|ruby-1.9.3-p448| isaacs-air in ~/git/yacn/dvm/tmp
± |fix/unable-to-stop-delete-containers ✗| → kitchen destroy
-----&amp;gt; Starting Kitchen (v1.2.1)
-----&amp;gt; Destroying &amp;lt;default-ubuntu&amp;gt;...
368ccd5979763ce38c072d9751417ba457827146548d7a04676b3a5795c806ca
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; ------Exception-------
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; Class: Kitchen::ActionFailed
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; Message: Failed to complete #destroy action: [Expected process to exit with [0], but received &amp;#39;1&amp;#39;
---- Begin output of docker -H tcp://192.168.42.43:4243 rm 368ccd5979763ce38c072d9751417ba457827146548d7a04676b3a5795c806ca ----
STDOUT:
STDERR: Error: container_delete: Cannot destroy container 368ccd5979763ce38c072d9751417ba457827146548d7a04676b3a5795c806ca: Driver aufs failed to remove root filesystem 368ccd5979763ce38c072d9751417ba457827146548d7a04676b3a5795c806ca: rename /var/lib/docker/aufs/mnt/368ccd5979763ce38c072d9751417ba457827146548d7a04676b3a5795c806ca /var/lib/docker/aufs/mnt/368ccd5979763ce38c072d9751417ba457827146548d7a04676b3a5795c806ca-removing: device or resource busy
2014/02/24 14:07:29 Error: failed to remove one or more containers
---- End output of docker -H tcp://192.168.42.43:4243 rm 368ccd5979763ce38c072d9751417ba457827146548d7a04676b3a5795c806ca ----
Ran docker -H tcp://192.168.42.43:4243 rm 368ccd5979763ce38c072d9751417ba457827146548d7a04676b3a5795c806ca returned 1]
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; ----------------------
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; Please see .kitchen/logs/kitchen.log for more details
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; Also try running `kitchen diagnose --all` for configuration
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Yikes, that doesn't seem good. Well, lets see if the container is still there. I logged into the &lt;code&gt;dvm&lt;/code&gt; machine via &lt;code&gt;dvm ssh&lt;/code&gt; and ran &lt;code&gt;docker ps&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;|ruby-1.9.3-p448| isaacs-air in ~/git/yacn/dvm/tmp
± |fix/unable-to-stop-delete-containers ✗| → dvm ssh
                        ##        .
                  ## ## ##       ==
               ## ## ## ##      ===
           /&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;\___/ ===
      ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ /  ===- ~~~
           \______ o          __/
             \    \        __/
              \____\______/
 _                 _   ____     _            _
| |__   ___   ___ | |_|___ \ __| | ___   ___| | _____ _ __
| &amp;#39;_ \ / _ \ / _ \| __| __) / _` |/ _ \ / __| |/ / _ \ &amp;#39;__|
| |_) | (_) | (_) | |_ / __/ (_| | (_) | (__|   &amp;lt;  __/ |
|_.__/ \___/ \___/ \__|_____\__,_|\___/ \___|_|\_\___|_|
boot2docker: 0.5.4
docker@boot2docker:~$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
docker@boot2docker:~$ exit
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Hmm, so it looks like the container was actually stopped. Researching this issue led me to &lt;a href=&quot;https://github.com/dotcloud/docker/issues/2714#issuecomment-34408878&quot;&gt;this&lt;/a&gt; thread. The issue seems to be related to using a symlink where Docker expects its runtime root to be. By default, this is &lt;code&gt;/var/lib/docker&lt;/code&gt;, but in boot2docker, this has been symlinked to &lt;code&gt;/mnt/sda/var/lib/docker&lt;/code&gt;. This causes Docker to be unable to stop or remove any of the containers it creates, as it doesn't seem to follow the symlink. &lt;/p&gt;&lt;p&gt;The remedy is to use the &lt;code&gt;-g&lt;/code&gt; option to set the path to use as the root of Docker's runtime to the directory the symlink points to. Looking at the file in boot2docker where the Docker daemon is started (&lt;a href=&quot;https://github.com/boot2docker/boot2docker/blob/master/rootfs/rootfs/usr/local/etc/init.d/docker#L18&quot;&gt;/usr/local/etc/init.d/docker&lt;/a&gt;), it seems like the &lt;code&gt;-g&lt;/code&gt; option should already be provided. All the more curious and needs further investigation.&lt;/p&gt;&lt;h2&gt;A &lt;code&gt;sed&lt;/code&gt; to far&lt;/h2&gt;&lt;p&gt;The culprit, it turns out, is the &lt;code&gt;Vagrantfile&lt;/code&gt; used by dvm! In the &lt;a href=&quot;https://github.com/fnichol/dvm/blob/master/Vagrantfile#L89&quot;&gt;provisioning script&lt;/a&gt; used to restart the Docker daemon with the args provided in &lt;code&gt;DOCKER_ARGS&lt;/code&gt;, there's a &lt;code&gt;sed&lt;/code&gt; command which looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sed -i -e &amp;#39;s|docker -d .* $EXPOSE_ALL|docker -d #{args}|&amp;#39; $INITD
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;where: &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;$INITD&lt;/code&gt; is &lt;code&gt;/usr/local/etc/init.d/docker&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;$EXPOSE_ALL&lt;/code&gt; is a variable set in that file&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;#{args}&lt;/code&gt; is the string interpolation of the &lt;code&gt;args&lt;/code&gt; defined in &lt;code&gt;DOCKER_ARGS&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This command is only run if you modify either &lt;code&gt;args&lt;/code&gt; or &lt;code&gt;DOCKER_ARGS&lt;/code&gt;, which is how I believe it slipped through the cracks.&lt;/p&gt;&lt;p&gt;What happens is the part of the line in &lt;code&gt;/usr/local/etc/init.d/docker&lt;/code&gt; that is specifying the &lt;code&gt;-g&lt;/code&gt; option is wiped out when the new &lt;code&gt;args&lt;/code&gt; are added to the command. There were a few options to solving this:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Update the README to state that if you modify &lt;code&gt;DOCKER_ARGS&lt;/code&gt;, you must make sure to include the &lt;code&gt;-g&lt;/code&gt; option&lt;/li&gt;
  &lt;li&gt;Update the &lt;code&gt;Vagrantfile&lt;/code&gt; to check if &lt;code&gt;DOCKER_ARGS&lt;/code&gt; is modified, and if so, to check that it includes the &lt;code&gt;-g&lt;/code&gt; option, adding it if it does not.&lt;/li&gt;
  &lt;li&gt;Update the &lt;code&gt;sed&lt;/code&gt; command to save the &lt;code&gt;-g&lt;/code&gt; option and use a backreference to it.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;I chose to implement option 3 as it seemed the simplest and most transparent way to accomplish the goal.&lt;/p&gt;&lt;h2&gt;One last run&lt;/h2&gt;&lt;p&gt;With the changes in place, it was time to test them out again. I created a new &lt;code&gt;dvm&lt;/code&gt; VM with the updated &lt;code&gt;Vagrantfile&lt;/code&gt; and a &lt;code&gt;dvm.conf&lt;/code&gt; specifying &lt;code&gt;DOCKER0_CIDR&lt;/code&gt;. Once that was created, I checked to make sure the &lt;code&gt;docker0&lt;/code&gt; bridge had the new IP range. So far, so good, so I ran &lt;code&gt;kitchen create&lt;/code&gt; and watched as Test Kitchen pulled in the Ubuntu repo and created a container for me. Still looking good, but all of this did work before. I enter &lt;code&gt;kitchen destroy&lt;/code&gt; for the final test and...&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;|ruby-1.9.3-p448| isaacs-air in ~/git/yacn/dvm/tmp
± |fix/unable-to-stop-delete-containers ✗| → kitchen destroy
-----&amp;gt; Starting Kitchen (v1.2.1)
-----&amp;gt; Destroying &amp;lt;default-ubuntu&amp;gt;...
2118a87d5cf2f5d6bc502a3f086b4ab828e6c3023624e2da9e8590eae043ec1f
2118a87d5cf2f5d6bc502a3f086b4ab828e6c3023624e2da9e8590eae043ec1f
Finished destroying &amp;lt;default-ubuntu&amp;gt; (0m0.14s).
-----&amp;gt; Kitchen is finished. (0m0.20s)

|ruby-1.9.3-p448| isaacs-air in ~/git/yacn/dvm/tmp
± |fix/unable-to-stop-delete-containers ✗| → kitchen list
Instance Driver Provisioner Last Action
default-ubuntu Docker ChefZero &amp;lt;Not Created&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;WooHoo! It works! &lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;To summarize, I needed to update dvm to allow me to set the IP range of the &lt;code&gt;docker0&lt;/code&gt; bridge. This required me to install bridge-utils for &lt;code&gt;brctl&lt;/code&gt; to remove the previously created &lt;code&gt;docker0&lt;/code&gt; bridge before my new IP range could take effect. Once that was implemented, I discovered a bug in the provisioning script for dvm causing which prevented stopping or deleting containers. Both fixes are currently open as pull requests:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/fnichol/dvm/pull/21&quot;&gt;sed fix&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/fnichol/dvm/pull/22&quot;&gt;Setting docker0 CIDR range&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Requirements Elicitation Experience: piperun</title><link>http://yacn.me/2014/02/23/requirement-elicitation-experience/</link><pubDate>Sun, 23 Feb 2014 00:00:00 -0500</pubDate><description>&lt;h1&gt;Requirements Elicitation Experience: piperun&lt;/h1&gt;&lt;p&gt;Near the end of my first co-op at &lt;a href=&quot;https://www.bitsighttech.com/&quot;&gt;BitSight&lt;/a&gt;, my manager had one last project for me: create a tool to generate the necessary configurations to aggregate data from an arbitrary date range. With this in mind, the first thing I set about doing was gathering all the expected functionality from the people I knew who would end up using it the most (namely, the QA and Data Science departments). I didn't realize it at the time, but I was performing requirement elicitation. The main method I used was brainstorming through a Google Doc which consisted of various user stories (&quot;As a BitSight engineer ...&quot;) for the various features requested.&lt;/p&gt;&lt;p&gt;Once I'd gathered enough requirements, I started putting together the MVP (minimum viable product), focusing most of my energy on generating the necessary datemask for the given date range. Unfortunately, I made a rookie mistake of rushing myself. I had heard a handful of times that the tool was needed because people were wanting to start using it, so I made the decision to write it in Ruby, the language I consider myself most proficient in. This was a mistake because my manager had specified the non-functional requirement that the tool must be written in Python as it would be maintained by the Engineering team and Python is the lingua franca around here. Luckily, most of my effort had been concentrated on developing the algorithm for datemask generation and it was trivial to port the work from Ruby to Python. Additionally, by writing my tests first (particularly for the datemask generation), it gave me peace of mind that the tool still performed as expected. As it turns out, this saved my skin! When testing out the tool with one of our Hadoop clusters, I found out I was generating the datemasks in the incorrect format (it was expecting ranges such as &lt;code&gt;[0-9]&lt;/code&gt; instead of bracket expansion ranges &lt;code&gt;{0..9}&lt;/code&gt;). I converted the tests to the new format, verified they all now failed, and then refactored the code to the new format, and verified all the tests passed! All said and done, the process took 5 minutes and definitely helped cement in my mind the importance of a thorough test suite.&lt;/p&gt;&lt;p&gt;In the end, the tool was released and continues to be used to this day!&lt;/p&gt;</description></item></channel></rss>